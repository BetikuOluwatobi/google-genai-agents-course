{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Observability - Plugins\n",
    " \n",
    "In this notebook, you'll learn:\n",
    "- How to develop the LoggingPlugin to add observability to an agent\n",
    "\n",
    "## What is Agent Observability?\n",
    "\n",
    "**ðŸš¨ The challenge:** Unlike traditional code, AI Agents are probabilisticâ€”they might run perfectly five times and crash on the sixth because the LLM decided to format a date differently or \"hallucinated\" a parameter. Example:\n",
    "\n",
    "```\n",
    "User: \"Book a flight to Paris for next Friday.\"\n",
    "Agent (Internal Tool Call): book_flight(title=\"flight\", date=\"next Friday\")\n",
    "System Response: ERROR: 400 Bad Request. Invalid format for 'date'. Expected YYYY-MM-DD, received 'next Friday'.\n",
    "Agent (to User): \"I'm sorry, I encountered a technical error and couldn't book the flight. Please try again later.\"\n",
    "You: ðŸ˜­ WHY?? Is it the prompt? Missing tools? API error?\n",
    "```\n",
    "\n",
    "**ðŸ’¡ The Solution:** Agent observability with ADK Logger Plugin gives you complete visibility into your agent's decision-making process. This plugin will hook into the agent's execution lifecycle phase to log exactly what prompts are sent to the LLM, which tools are available, how the model responds, and where failures occur.\n",
    "\n",
    "```\n",
    "DEBUG Log: LLM Request shows System Response: ERROR: 400 Bad Request. Invalid format for 'date'. Expected YYYY-MM-DD, received 'next Friday'.\n",
    "You: ðŸŽ¯ Aha! Wrong date format - easy fix!\n",
    "```\n",
    "\n",
    "## ADK Plugins\n",
    "\n",
    "ADK Plugins are a mechanism for implementing logic that intercepts, modifies, and even controls the agent's execution lifecycle. The plugin is composed of callback hooks, which are specific methods in your Plugin class that you can implement to run code at a key moment. You have a choice between two modes of operation based on your hook's return value:\n",
    "\n",
    "- To Observe: Implement a hook with no return value (None). This approach is for tasks such as logging or collecting metrics, as it allows the agent's workflow to proceed to the next step without interruption. For example, you could use after_tool_callback in a Plugin to log every tool's result for debugging.\n",
    "- To Intervene: Implement a hook and return a value. This approach short-circuits the workflow. The Runner halts processing, skips any subsequent plugins and the original intended action, like a Model call, and use a Plugin callback's return value as the result. A common use case is implementing before_model_callback to return a cached LlmResponse, preventing a redundant and costly API call.\n",
    "- To Amend: Implement a hook and modify the Context object. This approach allows you to modify the context data for the module to be executed without otherwise interrupting the execution of that module. For example, adding additional, standardized prompt text for Model object execution.\n",
    "\n",
    "**This notebook covers:**\n",
    "\n",
    "* âœ… Setting up logging configuration\n",
    "* âœ… Create a broken agent.\n",
    "* âœ… Understand how to implement logging in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install dependencies\n",
    "\n",
    "To install and use ADK in your own Python development environment, you can do so by running:\n",
    "\n",
    "```\n",
    "pip install google-adk\n",
    "```\n",
    "\n",
    "**Note**: If you cloned the repo and you use poetry, you do not need to do any installation, Read the project README.md on steps to run this notebook within the poetry environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure your Gemini API Key\n",
    "\n",
    "This notebook uses the [Gemini API](https://ai.google.dev/gemini-api/), which requires an API key.\n",
    "\n",
    "**1. Get your API key**\n",
    "\n",
    "If you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n",
    "\n",
    "**2. Add the key to your .env file**\n",
    "\n",
    "Next, you will need to add your API key to your .env file as a new secret with the variable `GOOGLE_API_KEY=api_key`.\n",
    "\n",
    "**3. Authenticate in the notebook**\n",
    "\n",
    "Run the cell below to access the `GOOGLE_API_KEY` you just saved and set it as a variable for the notebook to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load variables from .env\n",
    "\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logging and cleanup old files\n",
    "Let's configure logging for our debugging session. The following cell makes sure we also capture other log levels, like DEBUG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up agent_trace.log\n",
      "âœ… Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Clean up any previous logs\n",
    "for log_file in [\"logger.log\", \"web.log\", \"tunnel.log\", \"agent_trace.log\"]:\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "        print(f\"Cleaned up {log_file}\")\n",
    "\n",
    "# Configure logging with DEBUG log level.\n",
    "logging.basicConfig(\n",
    "    filename=\"agent_trace.log\",\n",
    "    level=logging.DEBUG,\n",
    "    # 1. Add %(asctime)s to the start of the format string\n",
    "    format=\"%(asctime)s %(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n",
    "    # 2. (Optional) Define a clean date format\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Logging configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Travel Concierge Agent\n",
    "\n",
    "\n",
    "**Goal:** Build a travel agent that provides personalized flight reservations for users.\n",
    "\n",
    "The code intentionally creates an incorrect version of the agent to practice debugging!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent definition\n",
    "\n",
    "Next, let's create our travel agent. \n",
    "- We'll configure it as an `LlmAgent`, give it a name, model, and instruction.\n",
    "- The `travel_agent` gets the user prompt and delegates the flight scheduling job to the `flight_agent`.\n",
    "- Then, the agent uses the `book_flight_tool` tool to simulate the external API that fails if the date format is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "\n",
    "from google.genai import types\n",
    "import random\n",
    "import string\n",
    "\n",
    "#A custom tool that inherits from AgentTool and handles the None case\n",
    "class SafeAgentTool(AgentTool):\n",
    "    async def run_async(self, args: dict, tool_context) -> str:\n",
    "        try:\n",
    "            # Call the original implementation\n",
    "            result = await super().run_async(args=args, tool_context=tool_context)\n",
    "            return result\n",
    "        except TypeError as e:\n",
    "            if \"NoneType\" in str(e):\n",
    "                # Handle the specific case where the sub-agent returns no text\n",
    "                return \"Agent execution completed, but no text summary was returned.\"\n",
    "            raise e\n",
    "\n",
    "def generate_random_alphanumeric(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choices(characters, k=length))\n",
    "\n",
    "def book_flight_api(destination: str, date: str):\n",
    "    \"\"\"\n",
    "    Simulates a legacy backend that is very strict about data formats.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Strict validation: Date must be YYYY-MM-DD\n",
    "    if not re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", date):\n",
    "        # This ValueError is what we want our LoggingPlugin to catch!\n",
    "        raise ValueError(f\"API Error: Invalid date format '{date}'. Backend expects strictly 'YYYY-MM-DD'.\")\n",
    "    \n",
    "    length = 6\n",
    "    reference_no = generate_random_alphanumeric(length)\n",
    "    return f\"Success: Flight to {destination} booked for {date}. PNR: {reference_no}\"\n",
    "\n",
    "# --- The \"Broken\" Tool Definition ---\n",
    "def book_flight_tool(destination: str, date: str):\n",
    "    \"\"\"\n",
    "    Books a flight ticket.\n",
    "    \n",
    "    Args:\n",
    "      destination: The destination city (e.g., 'London').\n",
    "      date: The intended date of departure. \n",
    "    \n",
    "    Returns:\n",
    "      Booking confirmation of the flight upon success, or error message on failure.\n",
    "    \"\"\"\n",
    "    # INTENTIONAL BUG:\n",
    "    # The docstring above is too vague. It says \"date\" but doesn't specify \"YYYY-MM-DD\".\n",
    "    # The LLM will guess the format (often incorrectly as \"Ded 12, 2025\"), causing the API to crash.\n",
    "    return book_flight_api(destination, date)\n",
    "\n",
    "# --- Agent Configuration ---\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "\n",
    "# Flight agent\n",
    "flight_agent = LlmAgent(\n",
    "    name=\"flight_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-lite\", retry_options=retry_config),\n",
    "    description=\"Handles flight bookings.\",\n",
    "    instruction=\"\"\"\n",
    "    You are a flight booking assistant. \n",
    "    Use the book_flight_tool to make reservations. \n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. If the tool returns a 'System Error', return the message to the root agent. Do NOT retry the tool!\n",
    "    2. Do not ask the user for the date format, just interpret their natural language request.\n",
    "    3. Return booking confirmation upon success.\n",
    "    \n",
    "    IMPORTANT: You MUST generate a final text summary for the user after the tool finishes. Do not return an empty response.\n",
    "    \"\"\",\n",
    "    tools=[book_flight_tool]\n",
    ")\n",
    "\n",
    "\n",
    "# Root agent\n",
    "travel_agent = LlmAgent(\n",
    "    name=\"travel_agent\",\n",
    "    model=Gemini(model=\"gemini-2.0-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"\n",
    "    You are the Lead Travel Coordinator.\n",
    "    1. Delegate flight requests to the flight_agent.\n",
    "    2. Pass the user's destination and date details exactly as provided. \n",
    "    3. Return both the booking confirmation and booking reference (PNP) if user asks.\n",
    "    \"\"\",\n",
    "    tools=[SafeAgentTool(agent=flight_agent)]\n",
    ")\n",
    "print(\"âœ… Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Plugin class\n",
    "\n",
    "We start by extending the BasePlugin class and add one or more callback methods, The callbacks are \"atomic\" (small, single-purpose) Python functions that act as hooks or interceptors. They pause the agent's flow at precise moments to run their code, then let the agent continue. Callbacks are grouped together to create a Plugin.\n",
    "\n",
    "There are different kinds of callbacks that give you control over different \"layers\" of the application such as:\n",
    "\n",
    "- **Agent Level (before/after_agent)**: Captures the start and end of the entire conversation turn.\n",
    "\n",
    "- **Tool Level (before/after_tool)**: Captures when the agent decides to \"do\" something, like search Google or query a database. This is critical for debugging why an agent gave a wrong answer based on bad data.\n",
    "\n",
    "- **Model Level (before/after_model)**: Captures the raw prompt sent to the LLM (e.g., GPT-4) and the raw response back. This can be used to track token usage (cost) and hallucination.\n",
    "\n",
    "- **Error Level (on_model_error)**: Triggers specifically if the LLM crashes or times out, allowing you to log the error gracefully without crashing the whole app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/plugins-callbacks.png)\n",
    "\n",
    "*Image Source: [kaggle-genai-intensive-course/day-4](https://github.com/geminii01/kaggle-genai-intensive-course/tree/main/day-4), Â© 2025*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents.base_agent import BaseAgent\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.events.event import Event\n",
    "from google.adk.models.llm_request import LlmRequest\n",
    "from google.adk.models.llm_response import LlmResponse\n",
    "from google.adk.tools.base_tool import BaseTool\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.plugins.base_plugin import BasePlugin\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "\n",
    "class LoggingPlugin(BasePlugin):\n",
    "    \"\"\"\n",
    "    A custom plugin that tracks the invocation status by logging:\n",
    "    - User messages and invocation context\n",
    "    - Agent execution flow\n",
    "    - LLM requests and responses\n",
    "    - Tool calls with arguments and results\n",
    "    - Events and final responses\n",
    "    - Errors during model and tool execution\n",
    "    \n",
    "    Example:\n",
    "      >>> logging_plugin = LoggingPlugin()\n",
    "      >>> runner = Runner(\n",
    "      ...     agents=[my_agent],\n",
    "      ...     # ...\n",
    "      ...     plugins=[logging_plugin],\n",
    "      ... )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str = \"logging_plugin\", logger: Optional[logging.Logger] = None):\n",
    "        \"Initialize the logging plugin.\"\n",
    "        super().__init__(name)\n",
    "        if logger:\n",
    "            self.logger = logger\n",
    "        else:\n",
    "            self.logger = logging\n",
    "\n",
    "    def _log(self, message: str, level: int = logging.INFO):\n",
    "        \"Helper to make logging cleaner.\"\n",
    "        self.logger.log(level, message)\n",
    "\n",
    "    def _format_content(self, content: Optional[types.Content]) -> str:\n",
    "        \"Format content for logging.\"\"\"\n",
    "        if not content or not content.parts:\n",
    "          return \"None\"\n",
    "        parts = []\n",
    "        for part in content.parts:\n",
    "            if part.text:\n",
    "                text = part.text.strip()\n",
    "                parts.append(f\"text: '{text}'\")\n",
    "            elif part.function_call:\n",
    "                parts.append(f\"function_call: {part.function_call.name}\")\n",
    "            elif part.function_response:\n",
    "                parts.append(f\"function_response: {part.function_response.name}\")\n",
    "            elif part.code_execution_result:\n",
    "                parts.append(\"code_execution_result\")\n",
    "            else:\n",
    "                parts.append(\"other_part\")\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    def _format_args(self, args: dict[str, Any]) -> str:\n",
    "        \"Format arguments dictionary for logging.\"\n",
    "        if not args:\n",
    "          return \"{}\"\n",
    "        \n",
    "        formatted = str(args)\n",
    "        return formatted\n",
    "\n",
    "    async def on_user_message_callback(\n",
    "        self, *, invocation_context: InvocationContext, user_message: types.Content\n",
    "    ) -> Optional[types.Content]:\n",
    "        \"Log user message and invocation start.\"\n",
    "        self._log(f\"ðŸš€ USER MESSAGE RECEIVED\", level=logging.INFO)\n",
    "        self._log(f\"Session ID: {invocation_context.session.id} | Invocation ID: {invocation_context.invocation_id}\", level=logging.INFO)\n",
    "        # DEBUG\n",
    "        self._log(f\"User Content: {self._format_content(user_message)}\", level=logging.DEBUG)\n",
    "        if invocation_context.branch:\n",
    "            self._log(f\"Branch: {invocation_context.branch}\", level=logging.DEBUG)\n",
    "        return None\n",
    "\n",
    "    async def before_run_callback(self, *, invocation_context: InvocationContext) -> Optional[types.Content]:\n",
    "        \"Log invocation start.\"\n",
    "        agent_name = getattr(invocation_context.agent, \"name\", \"Unknown\")\n",
    "        self._log(f\"ðŸƒ INVOCATION STARTING | Session ID: {invocation_context.session.id} | Invocation ID: {invocation_context.invocation_id}\", level=logging.INFO)\n",
    "        self._log(f\"Starting Agent: {agent_name}\", level=logging.INFO)\n",
    "        return None\n",
    "\n",
    "    async def on_event_callback(\n",
    "          self, *, invocation_context: InvocationContext, event: Event\n",
    "        ) -> Optional[Event]:\n",
    "        \"Log events yielded from the runner.\"\n",
    "        self._log(f\"ðŸ“¢ EVENT YIELDED (ID: {event.id})\", level=logging.INFO)\n",
    "        self._log(f\"Author: {event.author} | Final: {event.is_final_response()}\", level=logging.INFO)\n",
    "        self._log(f\"Content: {self._format_content(event.content)}\", level=logging.DEBUG)\n",
    "        if event.get_function_calls():\n",
    "            func_calls = [fc.name for fc in event.get_function_calls()]\n",
    "            self._log(f\"Function Calls: {func_calls}\", level=logging.INFO)\n",
    "        if event.get_function_responses():\n",
    "            func_responses = [fr.name for fr in event.get_function_responses()]\n",
    "            self._log(f\"Function Responses: {func_responses}\", level=logging.INFO)\n",
    "            self._log(f\"Full Function Response Data: {event.get_function_responses()}\", level=logging.DEBUG)\n",
    "        if event.long_running_tool_ids:\n",
    "            self._log(f\"Long Running Tools: {list(event.long_running_tool_ids)}\", level=logging.WARNING)\n",
    "        return None\n",
    "\n",
    "    async def after_run_callback(\n",
    "          self, *, invocation_context: InvocationContext\n",
    "        ) -> Optional[None]:\n",
    "        \"Log invocation completion.\"\n",
    "        agent_name = getattr(invocation_context.agent, \"name\", \"Unknown\")\n",
    "        self._log(\n",
    "            f\"âœ… INVOCATION COMPLETED | ID: {invocation_context.invocation_id} | Final Agent: {agent_name}\",\n",
    "            level=logging.INFO\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    async def before_agent_callback(\n",
    "          self, *, agent: BaseAgent, callback_context: CallbackContext\n",
    "        ) -> Optional[types.Content]:\n",
    "        \"Log agent execution start.\"\n",
    "        log_payload = {\n",
    "            \"agent_name\": callback_context.agent_name, \n",
    "            \"invocation_id\": callback_context.invocation_id\n",
    "        }\n",
    "        \n",
    "        if callback_context._invocation_context.branch:\n",
    "            log_payload[\"branch\"] = callback_context._invocation_context.branch\n",
    "            \n",
    "        self._log(f\"ðŸ¤– AGENT STARTING: {log_payload}\", level=logging.INFO)\n",
    "        return None\n",
    "\n",
    "    async def after_agent_callback(\n",
    "          self, *, agent: BaseAgent, callback_context: CallbackContext\n",
    "        ) -> Optional[types.Content]:\n",
    "        \"Log agent execution completion.\"\n",
    "        log_payload = {\n",
    "            \"agent_name\": callback_context.agent_name, \n",
    "            \"invocation_id\": callback_context.invocation_id\n",
    "        }\n",
    "        self._log(f\"ðŸ¤– AGENT COMPLETED: {log_payload}\", level=logging.INFO)\n",
    "        return None\n",
    "\n",
    "    async def before_model_callback(\n",
    "        self, *, callback_context: CallbackContext, llm_request: LlmRequest\n",
    "        ) -> Optional[LlmResponse]:\n",
    "        \"Log LLM request before sending to model.\"\n",
    "        # extract System Instruction\n",
    "        sys_instruction = \"None\"\n",
    "        if llm_request.config and llm_request.config.system_instruction:\n",
    "            sys_instruction = llm_request.config.system_instruction\n",
    "        # extract Tool Names \n",
    "        tool_names = list(llm_request.tools_dict.keys()) if llm_request.tools_dict else [\"None\"]\n",
    "        if tool_names == [\"None\"]:\n",
    "            self._log(\n",
    "                f\"âš ï¸ Configuration Warning: Agent '{callback_context.agent_name}' has no tools enabled.\", \n",
    "                level=logging.WARNING\n",
    "            )\n",
    "        # 3. Construct structured log message\n",
    "        log_message = (\n",
    "            f\"ðŸ§  LLM REQUEST DETAILS:\\n\"\n",
    "            f\"   â€¢ Agent: {callback_context.agent_name}\\n\"\n",
    "            f\"   â€¢ Model: {llm_request.model or 'default'}\\n\"\n",
    "            f\"   â€¢ Tools: {', '.join(tool_names)}\\n\"\n",
    "            f\"   â€¢ Sys Prompt: '{sys_instruction[:200]}'\"\n",
    "        )\n",
    "        self._log(log_message, level=logging.DEBUG)\n",
    "        return None\n",
    "\n",
    "    async def after_model_callback(\n",
    "        self, *, callback_context: CallbackContext, llm_response: LlmResponse\n",
    "    ) -> Optional[LlmResponse]:\n",
    "        \"Log LLM response after receiving from model.\"\n",
    "        agent_name = callback_context.agent_name\n",
    "        # If the LLM failed, log as ERROR and exit immediately\n",
    "        if llm_response.error_code and llm_response.error_code >= 400:\n",
    "            self._log(\n",
    "                f\"âŒ LLM ERROR for Agent '{agent_name}': \"\n",
    "                f\"Code {llm_response.error_code}, Message: {llm_response.error_message}\",\n",
    "                level=logging.ERROR\n",
    "            )\n",
    "            return None\n",
    "        # KPI & Usage Logging\n",
    "        usage = llm_response.usage_metadata\n",
    "        in_tokens = usage.prompt_token_count if usage else 0\n",
    "        out_tokens = usage.candidates_token_count if usage else 0\n",
    "        # Log event\n",
    "        self._log(\n",
    "            f\"ðŸ§  LLM RESPONSE received for Agent '{agent_name}'. \"\n",
    "            f\"Usage: [In: {in_tokens}, Out: {out_tokens}]\", \n",
    "            level=logging.INFO\n",
    "        )\n",
    "        # Verbose Debugging Data\n",
    "        formatted_content = self._format_content(llm_response.content)\n",
    "        debug_details = [\n",
    "            f\"ðŸ“„ Full Content: {formatted_content}\",\n",
    "        ]\n",
    "        # Add optional debug details only if they exist\n",
    "        if llm_response.partial:\n",
    "            debug_details.append(f\"Partial Response: {llm_response.partial}\")\n",
    "        if llm_response.turn_complete:\n",
    "            debug_details.append(f\"Turn Complete: {llm_response.turn_complete}\")\n",
    "        # Log all debug info\n",
    "        for detail in debug_details:\n",
    "            self._log(detail, level=logging.DEBUG)\n",
    "        return None\n",
    "\n",
    "    async def before_tool_callback(\n",
    "        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext,\n",
    "    ) -> Optional[dict]:       \n",
    "        \"Log BEFORE the tool is executed\"\n",
    "        # INFO log\n",
    "        log_header = (\n",
    "            f\"ðŸ”§ TOOL STARTING: [{tool.name}]\\n\"\n",
    "            f\"   â€¢ Agent: {tool_context.agent_name}\\n\"\n",
    "            f\"   â€¢ Call ID:    {tool_context.function_call_id}\"\n",
    "        )\n",
    "        self._log(log_header, level=logging.INFO)\n",
    "        # 2. DEBUG\n",
    "        self._log(\n",
    "            f\"   â€¢ Arguments: {self._format_args(tool_args)}\", level=logging.DEBUG\n",
    "        )\n",
    "        # 3. WARNING\n",
    "        if not tool_args:\n",
    "            self._log(\n",
    "                f\"âš ï¸  Warning: Tool '{tool.name}' was called without arguments.\", \n",
    "                level=logging.WARNING\n",
    "            )\n",
    "        return None\n",
    "\n",
    "    async def after_tool_callback(\n",
    "        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext, \n",
    "        result: dict,\n",
    "    ) -> Optional[dict]:\n",
    "        \"\"\"Log tool execution completion.\"\"\"\n",
    "        # INFO\n",
    "        log_header = (\n",
    "            f\"ðŸ”§ TOOL COMPLETED: {tool.name}\"\n",
    "            f\"   â€¢ Agent: {tool_context.agent_name}\\n\"\n",
    "            f\"   â€¢ Call ID:    {tool_context.function_call_id}\"\n",
    "        )\n",
    "        self._log(log_header, level=logging.INFO)\n",
    "        # DEBUG\n",
    "        self._log(\n",
    "            f\"   â€¢ Result: {self._format_args(result)}\", level=logging.DEBUG\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    async def on_model_error_callback(\n",
    "        self, *, callback_context: CallbackContext, llm_request: LlmRequest, \n",
    "        error: Exception,\n",
    "    ) -> Optional[LlmResponse]:\n",
    "        \"Log LLM error.\"\n",
    "        error_message = (\n",
    "            f\"ðŸ§  LLM ERROR in agent {callback_context.agent_name}\"\n",
    "            f\"   â€¢ Exception details: {error}\"\n",
    "        )\n",
    "        self._log(error_message, level=logging.ERROR)\n",
    "        self._log(f\"Payload causing error: {llm_request}\", level=logging.DEBUG)\n",
    "        fallback_content = types.Content(\n",
    "            role=\"model\",\n",
    "            parts=[types.Part(text=\"Sorry, I'm currently having trouble connecting to my brain. Please try again later.\")]\n",
    "        )\n",
    "        return LlmResponse(content=fallback_content)\n",
    "\n",
    "    async def on_tool_error_callback(\n",
    "        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext, \n",
    "        error: Exception,\n",
    "    ) -> Optional[dict]:\n",
    "        \"\"\"Log tool error.\"\"\"\n",
    "        self._log(\n",
    "            f\"ðŸ”§ TOOL ERROR: '{tool.name}' failed during execution.\\n\"\n",
    "            f\"Context: Agent '{tool_context.agent_name}' (ID: {tool_context.function_call_id})\\n\"\n",
    "            f\"Error Message: {error}\", level=logging.ERROR\n",
    "        )\n",
    "        self._log(\n",
    "            f\"ðŸ”§ TOOL ERROR DEBUG INFO - Arguments for '{tool.name}':\\n\"\n",
    "            f\"{self._format_args(tool_args)}\", level=logging.DEBUG\n",
    "        )\n",
    "        return {\"error\": f\"System Error: The tool failed to execute. Details: {str(error)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ Key Insights: The `LoggingPlugin` Architecture\n",
    "\n",
    "The `LoggingPlugin` class demonstrated above serves as a comprehensive **observability layer** for the Google ADK agent. Instead of scattering `print()` statements throughout the business logic, this plugin centralizes monitoring by leveraging ADK's **Lifecycle Callbacks**.\n",
    "\n",
    "Here is a breakdown of how it enhances the agent's robustness:\n",
    "\n",
    "#### 1. Full Observability (The \"Black Box\" Problem)\n",
    "\n",
    "AI Agents are often \"black boxes\", inputs go in, and answers come out, but the intermediate reasoning is lost. This plugin utilizes the `BasePlugin` inheritance to hook into every critical stage:\n",
    "\n",
    "* **Lifecycle Hooks:** It tracks the macro-flow (`before_run`, `after_run`) to measure total execution time per session.\n",
    "* **Decision Hooks:** It tracks the micro-flow (`before_model`, `after_model`) to see exactly what the LLM \"thought\" before acting.\n",
    "* **Action Hooks:** It tracks tool usage (`before_tool`, `after_tool`) to verify that the agent is passing the correct arguments to your APIs.\n",
    "\n",
    "#### 2. Tiered Logging Strategy\n",
    "\n",
    "The code implements a disciplined logging hierarchy that separates \"operational noise\" from \"critical signals\":\n",
    "\n",
    "* **`INFO`**: Used for high-level flow (e.g., *â€œAgent Started,â€* *â€œTool Calledâ€*). This is safe for production logs.\n",
    "* **`DEBUG`**: Used for heavy data payloads (e.g., *Full JSON arguments, raw prompt text*). This is essential for development, but should be disabled in production to save storage.\n",
    "* **`WARNING`**: Flags potential configuration issues, such as an agent defined with no tools (`before_model_callback`).\n",
    "\n",
    "#### 3. Cost & Performance Tracking\n",
    "\n",
    "In the `after_model_callback`, the plugin explicitly extracts `usage_metadata`:\n",
    "\n",
    "```python\n",
    "in_tokens = usage.prompt_token_count\n",
    "out_tokens = usage.candidates_token_count\n",
    "\n",
    "```\n",
    "\n",
    "This is critical for **FinOps**. It allows you to calculate the exact cost of every interaction and identify expensive queries or inefficient prompts.\n",
    "\n",
    "#### 4. Defensive Error Handling\n",
    "\n",
    "The plugin acts as a safety net. In the `on_model_error_callback`, rather than letting the application crash if the LLM is unreachable, it intercepts the exception and returns a fallback message:\n",
    "\n",
    "> *\"Sorry, I'm currently having trouble connecting to my brain...\"*\n",
    "\n",
    "This ensures the user experience remains smooth even during backend failures.\n",
    "\n",
    "#### 5. Context Propagation\n",
    "\n",
    "Notice how almost every log includes `invocation_context.session.id`. In a production environment with thousands of concurrent users, this ID allows you to filter logs and reconstruct a single conversation thread across distributed systems.\n",
    "\n",
    "### ðŸ’¡ Pro Tip for Implementation\n",
    "\n",
    "When adding this to your `Runner`, you can pass a custom logger instance. This allows you to route these specific agent logs to a separate file or a cloud monitoring service (like Google Cloud Logging) without interfering with your standard application logs.\n",
    "\n",
    "```python\n",
    "# Example Usage in Notebook\n",
    "my_logger = logging.getLogger(\"agent_debugger\")\n",
    "plugin = LoggingPlugin(logger=my_logger)\n",
    "\n",
    "```\n",
    "\n",
    "**Note**: Plugin callback functions have precedence over callbacks implemented at the object level. This behavior means that Any Plugin callbacks code is executed before any Agent, Model, or tool object callbacks are executed. Furthermore, if a Plugin-level agent callback returns any value, and not an empty (None) response, the Agent, Model, or Tool-level callback is not executed (skipped). Read more about Plugin hooks [here](https://google.github.io/adk-docs/plugins/#plugin-callback-hooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Add LoggingPlugin to Runner\n",
    "\n",
    "The following code creates the `InMemoryRunner`. This is used to programmatically invoke the agent.\n",
    "\n",
    "**To use `LoggingPlugin` in the above travel agent,**\n",
    "- Add it when initializing the `InMemoryRunner`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner configured with LoggingPlugin\n"
     ]
    }
   ],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Instead of using the \"root\" (default) logger, this creates a specific channel named \"agent_debugger\" for the agent\n",
    "# This allows you to filter these logs separately from system logs later if needed\n",
    "debug_logger = logging.getLogger(\"agent_debugger\")\n",
    "\n",
    "runner = InMemoryRunner(\n",
    "    agent=travel_agent,\n",
    "    plugins=[\n",
    "        LoggingPlugin(name=\"logging_plugin\", logger=debug_logger)\n",
    "    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner configured with LoggingPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "\n",
    "Let's now run our agent with the command in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTION LOOP\n",
    "# Since ADK runners are often async, we need an async loop to interact with it.\n",
    "async def run_interactive_session():\n",
    "    print(\"âœˆï¸ Travel Agent is ready! (Type 'quit' to exit)\")\n",
    "    \n",
    "    # Create a session ID (simple string for in-memory)\n",
    "    session_id = \"test-session-001\"\n",
    "\n",
    "    while True:\n",
    "        # Get input from the user\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "        # Send the message to the runner\n",
    "        # The runner handles: Plugin Hooks -> Agent Thinking -> Tool Calling -> Response\n",
    "        responses = await runner.run_debug(\n",
    "            user_messages=user_input,\n",
    "            session_id=session_id\n",
    "        )\n",
    "\n",
    "        # Print the final response from the agent\n",
    "        for response in responses:\n",
    "            # check for the parts\n",
    "            if response.content and response.content.parts:\n",
    "                for part in response.content.parts:\n",
    "                    # Case 1: Standard Text\n",
    "                    if part.text:\n",
    "                        print(f\"Agent: {part.text}\")\n",
    "                    \n",
    "                    # Case 2: Tool Call (Function Execution)\n",
    "                    # This happens if the agent decides to use a plugin/tool\n",
    "                    elif part.function_call:\n",
    "                        print(f\"ðŸ› ï¸  Agent is calling tool: {part.function_call.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœˆï¸ Travel Agent is ready! (Type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Book a flight to paris for next week friday.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: test-session-001\n",
      "\n",
      "User > Book a flight to paris for next week friday.\n",
      "travel_agent > Sorry, I'm currently having trouble connecting to my brain. Please try again later.\n",
      "Agent: Sorry, I'm currently having trouble connecting to my brain. Please try again later.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Why, did i miss any information?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Continue session: test-session-001\n",
      "\n",
      "User > Why, did i miss any information?\n",
      "travel_agent > Sorry, I'm currently having trouble connecting to my brain. Please try again later.\n",
      "Agent: Sorry, I'm currently having trouble connecting to my brain. Please try again later.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Run the async loop\n",
    "# If you are in a standard .py script, use 'asyncio.run(run_interactive_session())'\n",
    "# Book a flight to paris for next week friday, Why, did i miss any information?\n",
    "await run_interactive_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Evaluation\n",
    "\n",
    "To present the logs, we develop a Log Parser function that takes the raw text file created by the LoggingPlugin (agent_trace.log), reads it, and transforms it into a clean, readable table (DataFrame) so that we can analyze the agent's behavior without having to read thousands of lines of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Check the DEBUG logs from the broken agent\n",
    "def parse_logs_to_df(log_file):\n",
    "    log_pattern = re.compile(r'(?P<timestamp>[\\d\\- :]+) (?P<source>[\\w\\.]+:\\d+) (?P<level>\\w+):(?P<message>.*)')\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        with open(log_file, 'r') as f:\n",
    "            for line in f:\n",
    "                match = log_pattern.match(line)\n",
    "                if match:\n",
    "                    data.append(match.groupdict())\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>level</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2026-01-17 16:24:38</td>\n",
       "      <td>before_sleep.py:65</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.2584846706838 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2026-01-17 16:25:28</td>\n",
       "      <td>_client.py:1740</td>\n",
       "      <td>INFO</td>\n",
       "      <td>HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2026-01-17 16:25:28</td>\n",
       "      <td>before_sleep.py:65</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>_client.py:1740</td>\n",
       "      <td>INFO</td>\n",
       "      <td>HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>\\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>INFO</td>\n",
       "      <td>\\U0001f9e0 LLM RESPONSE received for Agent 'travel_agent'. Usage: [In: 0, Out: 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>INFO</td>\n",
       "      <td>\\U0001f4e2 EVENT YIELDED (ID: c438542a-1983-4ed4-be77-504bc42870b2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>INFO</td>\n",
       "      <td>Author: travel_agent | Final: True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>INFO</td>\n",
       "      <td>\\U0001f916 AGENT COMPLETED: {'agent_name': 'travel_agent', 'invocation_id': 'e-7595405a-8bc9-40ca-9741-f9e97b79b81a'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>INFO</td>\n",
       "      <td>\\u2705 INVOCATION COMPLETED | ID: e-7595405a-8bc9-40ca-9741-f9e97b79b81a | Final Agent: travel_agent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp              source  level  \\\n",
       "157  2026-01-17 16:24:38  before_sleep.py:65   INFO   \n",
       "170  2026-01-17 16:25:28     _client.py:1740   INFO   \n",
       "175  2026-01-17 16:25:28  before_sleep.py:65   INFO   \n",
       "188  2026-01-17 16:26:29     _client.py:1740   INFO   \n",
       "193  2026-01-17 16:26:29    3475425242.py:43  ERROR   \n",
       "196  2026-01-17 16:26:29    3475425242.py:43   INFO   \n",
       "198  2026-01-17 16:26:29    3475425242.py:43   INFO   \n",
       "199  2026-01-17 16:26:29    3475425242.py:43   INFO   \n",
       "201  2026-01-17 16:26:29    3475425242.py:43   INFO   \n",
       "202  2026-01-17 16:26:29    3475425242.py:43   INFO   \n",
       "\n",
       "                                                                                                                                                   message  \n",
       "157  Retrying google.genai._api_client.BaseApiClient._async_request_once in 49.2584846706838 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. ...  \n",
       "170      HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"  \n",
       "175  Retrying google.genai._api_client.BaseApiClient._async_request_once in 60.0 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'...  \n",
       "188      HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"  \n",
       "193                                                                                     \\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:   \n",
       "196                                                                      \\U0001f9e0 LLM RESPONSE received for Agent 'travel_agent'. Usage: [In: 0, Out: 0]  \n",
       "198                                                                                    \\U0001f4e2 EVENT YIELDED (ID: c438542a-1983-4ed4-be77-504bc42870b2)  \n",
       "199                                                                                                                     Author: travel_agent | Final: True  \n",
       "201                                  \\U0001f916 AGENT COMPLETED: {'agent_name': 'travel_agent', 'invocation_id': 'e-7595405a-8bc9-40ca-9741-f9e97b79b81a'}  \n",
       "202                                                   \\u2705 INVOCATION COMPLETED | ID: e-7595405a-8bc9-40ca-9741-f9e97b79b81a | Final Agent: travel_agent  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load logs\n",
    "df_logs = parse_logs_to_df(\"agent_trace.log\")\n",
    "\n",
    "if not df_logs.empty:\n",
    "    # Set display options to read long messages\n",
    "    pd.set_option('display.max_colwidth', 150)\n",
    "    \n",
    "    # 1. Filter for just the 'INFO' or 'ERROR' rows to show in your report\n",
    "    display_df = df_logs[df_logs['level'].isin(['INFO', 'ERROR', 'WARNING'])]\n",
    "    \n",
    "    # Display the last 10 relevant events\n",
    "    display(display_df.tail(10))\n",
    "else:\n",
    "    print(\"No logs found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>level</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2026-01-17 16:24:07</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>\\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2026-01-17 16:26:29</td>\n",
       "      <td>3475425242.py:43</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>\\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp            source  level  \\\n",
       "91   2026-01-17 16:24:07  3475425242.py:43  ERROR   \n",
       "193  2026-01-17 16:26:29  3475425242.py:43  ERROR   \n",
       "\n",
       "                                                                message  \n",
       "91   \\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:   \n",
       "193  \\U0001f9e0 LLM ERROR in agent travel_agent   â€¢ Exception details:   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(display_df[display_df[\"level\"]==\"ERROR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We've covered how to:**\n",
    "\n",
    "- âœ… Debug agent failures through DEBUG logs \n",
    "- âœ… Scale observability with `LoggingPlugin` for production systems\n",
    "- âœ… Understand when to use the different logging types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T01:50:15.542601Z",
     "iopub.status.busy": "2025-10-24T01:50:15.542221Z",
     "iopub.status.idle": "2025-10-24T01:50:15.548614Z",
     "shell.execute_reply": "2025-10-24T01:50:15.547556Z",
     "shell.execute_reply.started": "2025-10-24T01:50:15.542577Z"
    }
   },
   "source": [
    "### Resources\n",
    "\n",
    "**Refer to the ADK documentation to learn more about observability:**\n",
    "\n",
    "- [ADK Observability Documentation](https://google.github.io/adk-docs/observability/logging/) - Complete guide to logging in ADK\n",
    "- [Custom Plugin](https://google.github.io/adk-docs/plugins/) - Build your own Plugins\n",
    "- [External Integrations](https://google.github.io/adk-docs/observability/cloud-trace/) - Explore external third-party observability integrations with ADK"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
