{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T19:15:08.149281Z","iopub.execute_input":"2025-11-12T19:15:08.149605Z","iopub.status.idle":"2025-11-12T19:15:08.155172Z","shell.execute_reply.started":"2025-11-12T19:15:08.149581Z","shell.execute_reply":"2025-11-12T19:15:08.154081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Agent Observability - Plugins\n \nIn this notebook, you'll learn:\n- How to develop the LoggingPlugin to add observability to an agent\n\n## What is Agent Observability?\n\n**ðŸš¨ The challenge:** Unlike traditional code, AI Agents are probabilisticâ€”they might run perfectly five times and crash on the sixth because the LLM decided to format a date differently or \"hallucinated\" a parameter. Example:\n\n```\nUser: \"Book a flight to Paris for next Friday.\"\nAgent (Internal Tool Call): book_flight(title=\"flight\", date=\"next Friday\")\nSystem Response: ERROR: 400 Bad Request. Invalid format for 'date'. Expected YYYY-MM-DD, received 'next Friday'.\nAgent (to User): \"I'm sorry, I encountered a technical error and couldn't book the flight. Please try again later.\"\nYou: ðŸ˜­ WHY?? Is it the prompt? Missing tools? API error?\n```\n\n**ðŸ’¡ The Solution:** Agent observability with ADK Logger Plugin gives you complete visibility into your agent's decision-making process. This plugin will hook into the agent's execution lifecycle phase to log exactly what prompts are sent to the LLM, which tools are available, how the model responds, and where failures occur.\n\n```\nDEBUG Log: LLM Request shows System Response: ERROR: 400 Bad Request. Invalid format for 'date'. Expected YYYY-MM-DD, received 'next Friday'.\nYou: ðŸŽ¯ Aha! Wrong date format - easy fix!\n```\n\n## ADK Plugins\n\nADK Plugins are a mechanism for implementing logic that intercepts, modifies, and even controls the agent's execution lifecycle. The plugin is composed of callback hooks, which are specific methods in your Plugin class that you can implement to run code at a key moment. You have a choice between two modes of operation based on your hook's return value:\n\n- To Observe: Implement a hook with no return value (None). This approach is for tasks such as logging or collecting metrics, as it allows the agent's workflow to proceed to the next step without interruption. For example, you could use after_tool_callback in a Plugin to log every tool's result for debugging.\n- To Intervene: Implement a hook and return a value. This approach short-circuits the workflow. The Runner halts processing, skips any subsequent plugins and the original intended action, like a Model call, and use a Plugin callback's return value as the result. A common use case is implementing before_model_callback to return a cached LlmResponse, preventing a redundant and costly API call.\n- To Amend: Implement a hook and modify the Context object. This approach allows you to modify the context data for the module to be executed without otherwise interrupting the execution of that module. For example, adding additional, standardized prompt text for Model object execution.\n\n**This notebook covers:**\n\n* âœ… Setting up logging configuration\n* âœ… Create a broken agent.\n* âœ… Understand how to implement logging in production","metadata":{}},{"cell_type":"markdown","source":"## Setup\n\n### Install dependencies\n\nTo install and use ADK in your own Python development environment, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/), which requires an API key.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to your .env file**\n\nNext, you will need to add your API key to your .env file as a new secret with the variable `GOOGLE_API_KEY=api_key`.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to access the `GOOGLE_API_KEY` you just saved and set it as a variable for the notebook to use.","metadata":{}},{"cell_type":"code","source":"import os, time\nfrom dotenv import load_dotenv\nload_dotenv()  # Load variables from .env\n\nGOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Set up logging and cleanup old files\nLet's configure logging for our debugging session. The following cell makes sure we also capture other log levels, like DEBUG.","metadata":{}},{"cell_type":"code","source":"import logging\n\n# Clean up any previous logs\nfor log_file in [\"logger.log\", \"web.log\", \"tunnel.log\"]:\n    if os.path.exists(log_file):\n        os.remove(log_file)\n        print(f\"Cleaned up {log_file}\")\n\n# Configure logging with DEBUG log level.\nlogging.basicConfig(\n    filename=\"agent_trace.log\",\n    level=logging.DEBUG,\n    # 1. Add %(asctime)s to the start of the format string\n    format=\"%(asctime)s %(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n    # 2. (Optional) Define a clean date format\n    datefmt=\"%Y-%m-%d %H:%M:%S\"\n)\n\nprint(\"âœ… Logging configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T19:15:08.280623Z","iopub.execute_input":"2025-11-12T19:15:08.280848Z","iopub.status.idle":"2025-11-12T19:15:08.287816Z","shell.execute_reply.started":"2025-11-12T19:15:08.28083Z","shell.execute_reply":"2025-11-12T19:15:08.286586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create the Travel Concierge Agent\n\n\n**Goal:** Build a travel agent that provides personalized flight reservations for users.\n\nThe code intentionally creates an incorrect version of the agent to practice debugging!","metadata":{}},{"cell_type":"markdown","source":"### Agent definition\n\nNext, let's create our root agent. \n- We'll configure it as an `LlmAgent`, give it a name, model, and instruction.\n- The `travel_agent` gets the user prompt and delegates the flight scheduling job to the `flight_agent`.\n- Then, the agent uses the `book_flight_tool` tool to simulate the external API that fails if the date format is wrong.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.google_search_tool import google_search\n\nfrom google.genai import types\nfrom typing import List\nimport random\nimport string\n\ndef generate_random_alphanumeric(length):\n    characters = string.ascii_letters + string.digits\n    return ''.join(random.choices(characters, k=length))\n\ndef book_flight_api(destination: str, date: str):\n    \"\"\"\n    Simulates a legacy backend that is very strict about data formats.\n    \"\"\"\n    import re\n    # Strict validation: Date must be YYYY-MM-DD\n    if not re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", date):\n        # This ValueError is what we want our LoggingPlugin to catch!\n        raise ValueError(f\"API Error: Invalid date format '{date}'. Backend expects strictly 'YYYY-MM-DD'.\")\n    \n    length = 6\n    reference_no = generate_random_alphanumeric(length)\n    return f\"Success: Flight to {destination} booked for {date}. PNR: {reference_no}\"\n\n# --- The \"Broken\" Tool Definition ---\ndef book_flight_tool(destination: str, date: str):\n    \"\"\"\n    Books a flight ticket.\n    \n    Args:\n      destination: The destination city (e.g., 'London').\n      date: The intended date of departure. \n    \n    Returns:\n      Booking confirmation of the flight upon success.\n    \"\"\"\n    # INTENTIONAL BUG: \n    # The docstring above is too vague. It says \"date\" but doesn't specify \"YYYY-MM-DD\".\n    # The LLM will guess the format (often incorrectly as \"Oct 12, 2025\"), causing the API to crash.\n    return book_flight_api(destination, date)\n\n# --- Agent Configuration ---\nretry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)\n\n# Flight agent\nflight_agent = LlmAgent(\n    name=\"flight_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Handles flight bookings.\",\n    instruction=\"\"\"\n    You are a flight booking assistant. \n    Use the book_flight_tool to make reservations. \n    Do not ask the user for the date format, just interpret their natural language request.\n    Return booking confirmation upon success.\n    If the user asks for a booking reference (PNR), then give them the unique 6-character alphanumeric code (e.g., 4YUK3R, A12BC3, K6PMQI) from the flight reservation confirmation.\n    \"\"\",\n    tools=[book_flight_tool]\n)\n\n\n# Root agent\ntravel_agent = LlmAgent(\n    name=\"travel_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"\n    You are the Lead Travel Coordinator.\n    1. Delegate flight requests to the flight_agent.\n    2. Pass the user's destination and date details exactly as provided. \n    3. Return both the booking confirmation and booking reference (PNP) if user asks.\n    \"\"\",\n    tools=[AgentTool(agent=flight_agent)]\n)\nprint(\"âœ… Agent created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T19:15:57.920313Z","iopub.execute_input":"2025-11-12T19:15:57.920709Z","iopub.status.idle":"2025-11-12T19:15:57.929037Z","shell.execute_reply.started":"2025-11-12T19:15:57.920678Z","shell.execute_reply":"2025-11-12T19:15:57.928058Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Create the Plugin class\n\nWe start by extending the BasePlugin class and add one or more callback methods, The callbacks are \"atomic\" (small, single-purpose) Python functions that act as hooks or interceptors. They pause the agent's flow at precise moments to run their code, then let the agent continue. Callbacks are grouped together to create a Plugin.\n\nThere are different kinds of callbacks that give you control over different \"layers\" of the application such as:\n\n- **Agent Level (before/after_agent)**: Captures the start and end of the entire conversation turn.\n\n- **Tool Level (before/after_tool)**: Captures when the agent decides to \"do\" something, like search Google or query a database. This is critical for debugging why an agent gave a wrong answer based on bad data.\n\n- **Model Level (before/after_model)**: Captures the raw prompt sent to the LLM (e.g., GPT-4) and the raw response back. This can be used to track token usage (cost) and hallucination.\n\n- **Error Level (on_model_error)**: Triggers specifically if the LLM crashes or times out, allowing you to log the error gracefully without crashing the whole app.","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/plugins-callbacks.png)\n\n*Image Source: [kaggle-genai-intensive-course/day-4](https://github.com/geminii01/kaggle-genai-intensive-course/tree/main/day-4), Â© 2025*","metadata":{}},{"cell_type":"code","source":"from typing import Any, Optional\nfrom google.genai import types\n\nfrom google.adk.base_agent import BaseAgent\nfrom google.adk.callback_context import CallbackContext\nfrom google.adk.events.event import Event\nfrom google.adk.models.llm_request import LlmRequest\nfrom google.adk.models.llm_response import LlmResponse\nfrom google.adk.tools.base_tool import BaseTool\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.adk.base_plugin import BasePlugin\nfrom google.adk.agents.invocation_context import InvocationContext\n\nclass LoggingPlugin(BasePlugin):\n    \"\"\"\n    A custom plugin that tracks the invocation status by logging:\n    - User messages and invocation context\n    - Agent execution flow\n    - LLM requests and responses\n    - Tool calls with arguments and results\n    - Events and final responses\n    - Errors during model and tool execution\n    \n    Example:\n      >>> logging_plugin = LoggingPlugin()\n      >>> runner = Runner(\n      ...     agents=[my_agent],\n      ...     # ...\n      ...     plugins=[logging_plugin],\n      ... )\n    \"\"\"\n\n    def __init__(self, name: str = \"logging_plugin\", logger: Optional[logging.Logger] = None):\n        \"Initialize the logging plugin.\"\n        super().__init__(name)\n        if logger:\n            self.logger = logger\n        else:\n            self.logger = logging\n\n    def _log(self, message: str, level: int = logging.INFO):\n        \"Helper to make logging cleaner.\"\n        self.logger.log(level, message)\n\n    def _format_content(self, content: Optional[types.Content]) -> str:\n        \"Format content for logging, truncating if too long.\"\"\"\n        if not content or not content.parts:\n          return \"None\"\n        parts = []\n        for part in content.parts:\n            if part.text:\n                text = part.text.strip()\n                parts.append(f\"text: '{text}'\")\n            elif part.function_call:\n                parts.append(f\"function_call: {part.function_call.name}\")\n            elif part.function_response:\n                parts.append(f\"function_response: {part.function_response.name}\")\n            elif part.code_execution_result:\n                parts.append(\"code_execution_result\")\n            else:\n                parts.append(\"other_part\")\n        return \" | \".join(parts)\n\n    def _format_args(self, args: dict[str, Any]) -> str:\n        \"Format arguments dictionary for logging.\"\n        if not args:\n          return \"{}\"\n        \n        formatted = str(args)\n        return formatted\n\n    async def on_user_message_callback(\n        self, *, invocation_context: InvocationContext, user_message: types.Content\n    ) -> Optional[types.Content]:\n        \"Log user message and invocation start.\"\n        self._log(f\"ðŸš€ USER MESSAGE RECEIVED\", level=logging.INFO)\n        self._log(f\"Session ID: {invocation_context.session.id} | Invocation ID: {invocation_context.invocation_id}\", level=logging.INFO)\n        # DEBUG\n        self._log(f\"User Content: {self._format_content(user_message)}\", level=logging.DEBUG)\n        if invocation_context.branch:\n            self._log(f\"Branch: {invocation_context.branch}\", level=logging.DEBUG)\n        return None\n\n    async def before_run_callback(self, *, invocation_context: InvocationContext) -> Optional[types.Content]:\n        \"Log invocation start.\"\n        self._log(f\"ðŸƒ INVOCATION STARTING\", level=logging.INFO)\n        self._log(f\"Session ID: {invocation_context.session.id} | Invocation ID: {invocation_context.invocation_id}\", level=logging.INFO)\n        self._log(\n            f\"Starting Agent: {invocation_context.agent.name if hasattr(invocation_context.agent, 'name') else 'Unknown'}\",\n            level=logging.INFO\n        )\n        return None\n\n    async def on_event_callback(\n          self, *, invocation_context: InvocationContext, event: Event\n        ) -> Optional[Event]:\n        \"Log events yielded from the runner.\"\n        self._log(f\"ðŸ“¢ EVENT YIELDED (ID: {event.id})\", level=logging.INFO)\n        self._log(f\"Author: {event.author} | Final: {event.is_final_response()}\", level=logging.INFO)\n        self._log(f\"Content: {self._format_content(event.content)}\", level=logging.DEBUG)\n        if event.get_function_calls():\n            func_calls = [fc.name for fc in event.get_function_calls()]\n            self._log(f\"Function Calls: {func_calls}\", level=logging.INFO)\n        if event.get_function_responses():\n            func_responses = [fr.name for fr in event.get_function_responses()]\n            self._log(f\"Function Responses: {func_responses}\", level=logging.INFO)\n            self._log(f\"Full Function Response Data: {event.get_function_responses()}\", level=logging.DEBUG)\n        if event.long_running_tool_ids:\n            self._log(f\"Long Running Tools: {list(event.long_running_tool_ids)}\", level=logging.WARNING)\n        return None\n\n    async def after_run_callback(\n          self, *, invocation_context: InvocationContext\n        ) -> Optional[None]:\n        \"Log invocation completion.\"\n        agent_name = getattr(invocation_context.agent, \"name\", \"Unknown\")\n        self._log(\n            f\"âœ… INVOCATION COMPLETED | ID: {invocation_context.invocation_id} | Final Agent: {agent_name}\",\n            level=logging.INFO\n        )\n        return None\n\n    async def before_agent_callback(\n          self, *, agent: BaseAgent, callback_context: CallbackContext\n        ) -> Optional[types.Content]:\n        \"Log agent execution start.\"\n        log_payload = {\n            \"agent_name\": callback_context.agent_name, \n            \"invocation_id\": callback_context.invocation_id\n        }\n        \n        if callback_context._invocation_context.branch:\n            log_payload[\"branch\"] = callback_context._invocation_context.branch\n            \n        self._log(f\"ðŸ¤– AGENT STARTING: {log_payload}\", level=logging.INFO)\n        return None\n\n    async def after_agent_callback(\n          self, *, agent: BaseAgent, callback_context: CallbackContext\n        ) -> Optional[types.Content]:\n        \"Log agent execution completion.\"\n        log_payload = {\n            \"agent_name\": callback_context.agent_name, \n            \"invocation_id\": callback_context.invocation_id\n        }\n        self._log(f\"ðŸ¤– AGENT COMPLETED: {log_payload}\", level=logging.INFO)\n        return None\n\n    async def before_model_callback(\n        self, *, callback_context: CallbackContext, llm_request: LlmRequest\n        ) -> Optional[LlmResponse]:\n        \"Log LLM request before sending to model.\"\n        # extract System Instruction\n        sys_instruction = \"None\"\n        if llm_request.config and llm_request.config.system_instruction:\n            sys_instruction = llm_request.config.system_instruction\n        # extract Tool Names \n        tool_names = list(llm_request.tools_dict.keys()) if llm_request.tools_dict else [\"None\"]\n        if tool_names == [\"None\"]:\n            self._log(\n                f\"âš ï¸ Configuration Warning: Agent '{callback_context.agent_name}' has no tools enabled.\", \n                level=logging.WARNING\n            )\n        # 3. Construct structured log message\n        log_message = (\n            f\"ðŸ§  LLM REQUEST DETAILS:\\n\"\n            f\"   â€¢ Agent: {callback_context.agent_name}\\n\"\n            f\"   â€¢ Model: {llm_request.model or 'default'}\\n\"\n            f\"   â€¢ Tools: {', '.join(tool_names)}\\n\"\n            f\"   â€¢ Sys Prompt: '{sys_instruction[:200]}'\"\n        )\n        self._log(log_message, level=logging.DEBUG)\n        return None\n\n    async def after_model_callback(\n        self, *, callback_context: CallbackContext, llm_response: LlmResponse\n    ) -> Optional[LlmResponse]:\n        \"Log LLM response after receiving from model.\"\n        agent_name = callback_context.agent_name\n        # If the LLM failed, log as ERROR and exit immediately\n        if llm_response.error_code and llm_response.error_code >= 400:\n            self._log(\n                f\"âŒ LLM ERROR for Agent '{agent_name}': \"\n                f\"Code {llm_response.error_code}, Message: {llm_response.error_message}\",\n                level=logging.ERROR\n            )\n            return None\n        # KPI & Usage Logging\n        usage = llm_response.usage_metadata\n        in_tokens = usage.prompt_token_count if usage else 0\n        out_tokens = usage.candidates_token_count if usage else 0\n        # Log event\n        self._log(\n            f\"ðŸ§  LLM RESPONSE received for Agent '{agent_name}'. \"\n            f\"Usage: [In: {in_tokens}, Out: {out_tokens}]\", \n            level=logging.INFO\n        )\n        # Verbose Debugging Data\n        formatted_content = self._format_content(llm_response.content)\n        debug_details = [\n            f\"ðŸ“„ Full Content: {formatted_content}\",\n        ]\n        # Add optional debug details only if they exist\n        if llm_response.partial:\n            debug_details.append(f\"Partial Response: {llm_response.partial}\")\n        if llm_response.turn_complete:\n            debug_details.append(f\"Turn Complete: {llm_response.turn_complete}\")\n        # Log all debug info\n        for detail in debug_details:\n            self._log(detail, level=logging.DEBUG)\n        return None\n\n    async def before_tool_callback(\n        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext,\n    ) -> Optional[dict]:       \n        \"Log BEFORE the tool is executed\"\n        # INFO log\n        log_header = (\n            f\"ðŸ”§ TOOL STARTING: [{tool.name}]\\n\"\n            f\"   â€¢ Agent: {tool_context.agent_name}\\n\"\n            f\"   â€¢ Call ID:    {tool_context.function_call_id}\"\n        )\n        self._log(log_header, level=logging.INFO)\n        # 2. DEBUG\n        self._log(\n            f\"   â€¢ Arguments: {self._format_args(tool_args)}\", level=logging.DEBUG\n        )\n        # 3. WARNING\n        if not tool_args:\n            self._log(\n                f\"âš ï¸  Warning: Tool '{tool.name}' was called without arguments.\", \n                level=logging.WARNING\n            )\n        return None\n\n    async def after_tool_callback(\n        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext, \n        result: dict,\n    ) -> Optional[dict]:\n        \"\"\"Log tool execution completion.\"\"\"\n        # INFO\n        log_header = (\n            f\"ðŸ”§ TOOL COMPLETED: {tool.name}\"\n            f\"   â€¢ Agent: {tool_context.agent_name}\\n\"\n            f\"   â€¢ Call ID:    {tool_context.function_call_id}\"\n        )\n        self._log(log_header, level=logging.INFO)\n        # DEBUG\n        self._log(\n            f\"   â€¢ Result: {self._format_args(result)}\", level=logging.DEBUG\n        )\n        return None\n\n    async def on_model_error_callback(\n        self, *, callback_context: CallbackContext, llm_request: LlmRequest, \n        error: Exception,\n    ) -> Optional[LlmResponse]:\n        \"Log LLM error.\"\n        error_message = (\n            f\"ðŸ§  LLM ERROR in agent {callback_context.agent_name}\"\n            f\"   â€¢ Exception details: {error}\"\n        )\n        self._log(error_message, level=logging.ERROR)\n        self._log(f\"Payload causing error: {llm_request}\", level=logging.DEBUG)\n        return LlmResponse(content=\"Sorry, I'm currently having trouble connecting to my brain. Please try again later.\")\n\n    async def on_tool_error_callback(\n        self, *, tool: BaseTool, tool_args: dict[str, Any], tool_context: ToolContext, \n        error: Exception,\n    ) -> Optional[dict]:\n        \"\"\"Log tool error.\"\"\"\n        self._log(\n            f\"ðŸ”§ TOOL ERROR: '{tool.name}' failed during execution.\\n\"\n            f\"Context: Agent '{tool_context.agent_name}' (ID: {tool_context.function_call_id})\\n\"\n            f\"Error Message: {error}\", level=logging.ERROR\n        )\n        self._log(\n            f\"ðŸ”§ TOOL ERROR DEBUG INFO - Arguments for '{tool.name}':\\n\"\n            f\"{self._format_args(tool_args)}\", level=logging.DEBUG\n        )\n        return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ“ Key Insights: The `LoggingPlugin` Architecture\n\nThe `LoggingPlugin` class demonstrated above serves as a comprehensive **observability layer** for the Google ADK agent. Instead of scattering `print()` statements throughout the business logic, this plugin centralizes monitoring by leveraging ADK's **Lifecycle Callbacks**.\n\nHere is a breakdown of how it enhances the agent's robustness:\n\n#### 1. Full Observability (The \"Black Box\" Problem)\n\nAI Agents are often \"black boxes\", inputs go in, and answers come out, but the intermediate reasoning is lost. This plugin utilizes the `BasePlugin` inheritance to hook into every critical stage:\n\n* **Lifecycle Hooks:** It tracks the macro-flow (`before_run`, `after_run`) to measure total execution time per session.\n* **Decision Hooks:** It tracks the micro-flow (`before_model`, `after_model`) to see exactly what the LLM \"thought\" before acting.\n* **Action Hooks:** It tracks tool usage (`before_tool`, `after_tool`) to verify that the agent is passing the correct arguments to your APIs.\n\n#### 2. Tiered Logging Strategy\n\nThe code implements a disciplined logging hierarchy that separates \"operational noise\" from \"critical signals\":\n\n* **`INFO`**: Used for high-level flow (e.g., *â€œAgent Started,â€* *â€œTool Calledâ€*). This is safe for production logs.\n* **`DEBUG`**: Used for heavy data payloads (e.g., *Full JSON arguments, raw prompt text*). This is essential for development, but should be disabled in production to save storage.\n* **`WARNING`**: Flags potential configuration issues, such as an agent defined with no tools (`before_model_callback`).\n\n#### 3. Cost & Performance Tracking\n\nIn the `after_model_callback`, the plugin explicitly extracts `usage_metadata`:\n\n```python\nin_tokens = usage.prompt_token_count\nout_tokens = usage.candidates_token_count\n\n```\n\nThis is critical for **FinOps**. It allows you to calculate the exact cost of every interaction and identify expensive queries or inefficient prompts.\n\n#### 4. Defensive Error Handling\n\nThe plugin acts as a safety net. In the `on_model_error_callback`, rather than letting the application crash if the LLM is unreachable, it intercepts the exception and returns a fallback message:\n\n> *\"Sorry, I'm currently having trouble connecting to my brain...\"*\n\nThis ensures the user experience remains smooth even during backend failures.\n\n#### 5. Context Propagation\n\nNotice how almost every log includes `invocation_context.session.id`. In a production environment with thousands of concurrent users, this ID allows you to filter logs and reconstruct a single conversation thread across distributed systems.\n\n### ðŸ’¡ Pro Tip for Implementation\n\nWhen adding this to your `Runner`, you can pass a custom logger instance. This allows you to route these specific agent logs to a separate file or a cloud monitoring service (like Google Cloud Logging) without interfering with your standard application logs.\n\n```python\n# Example Usage in Notebook\nmy_logger = logging.getLogger(\"agent_debugger\")\nplugin = LoggingPlugin(logger=my_logger)\n\n```\n\n**Note**: Plugin callback functions have precedence over callbacks implemented at the object level. This behavior means that Any Plugin callbacks code is executed before any Agent, Model, or tool object callbacks are executed. Furthermore, if a Plugin-level agent callback returns any value, and not an empty (None) response, the Agent, Model, or Tool-level callback is not executed (skipped). Read more about Plugin hooks [here](https://google.github.io/adk-docs/plugins/#plugin-callback-hooks).","metadata":{}},{"cell_type":"markdown","source":"### 3.4: Add LoggingPlugin to Runner\n\nThe following code creates the `InMemoryRunner`. This is used to programmatically invoke the agent.\n\n**To use `LoggingPlugin` in the above travel agent,**\n- Add it when initializing the `InMemoryRunner`.\n","metadata":{}},{"cell_type":"code","source":"from google.adk.runners import InMemoryRunner\nfrom google.genai import types\nimport asyncio\n\n\n# Instead of using the \"root\" (default) logger, this creates a specific channel named \"agent_debugger\" for the agent\n# This allows you to filter these logs separately from system logs later if needed\ndebug_logger = logging.getLogger(\"agent_debugger\")\n\nrunner = InMemoryRunner(\n    agent=travel_agent,\n    plugins=[\n        LoggingPlugin(name=\"logging_plugin\", logger=debug_logger)\n    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents\n)\n\nprint(\"âœ… Runner configured with LoggingPlugin\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Run the agent\n\nLet's now run our agent with the command in the next cell.","metadata":{}},{"cell_type":"code","source":"# EXECUTION LOOP\n# Since ADK runners are often async, we need an async loop to interact with it.\nasync def run_interactive_session():\n    print(\"âœˆï¸ Travel Agent is ready! (Type 'quit' to exit)\")\n    \n    # Create a session ID (simple string for in-memory)\n    session_id = \"test-session-001\"\n\n    while True:\n        # Get input from the user\n        user_input = input(\"You: \")\n        if user_input.lower() in [\"quit\", \"exit\"]:\n            print(\"Exiting...\")\n            break\n\n        # Send the message to the runner\n        # The runner handles: Plugin Hooks -> Agent Thinking -> Tool Calling -> Response\n        responses = await runner.run(\n            input=user_input,\n            session_id=session_id\n        )\n\n        # Print the final text response from the agent\n        for response in responses:\n            print(f\"Agent: {response.content}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the async loop\n# If you are in a standard .py script, use 'asyncio.run(run_interactive_session())'\nawait run_interactive_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T19:16:50.568034Z","iopub.execute_input":"2025-11-12T19:16:50.568333Z","iopub.status.idle":"2025-11-12T19:16:57.577725Z","shell.execute_reply.started":"2025-11-12T19:16:50.568307Z","shell.execute_reply":"2025-11-12T19:16:57.576751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Log Evaluation\n\nTo present the logs, we develop a Log Parser function that takes the raw text file created by the LoggingPlugin (agent_trace.log), reads it, and transforms it into a clean, readable table (DataFrame) so that we can analyze the agent's behavior without having to read thousands of lines of text.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Check the DEBUG logs from the broken agent\ndef parse_logs_to_df(log_file):\n    log_pattern = re.compile(r'(?P<timestamp>[\\d\\- :]+) (?P<source>[\\w\\.]+:\\d+) (?P<level>\\w+):(?P<message>.*)')\n    data = []\n\n    try:\n        with open(log_file, 'r') as f:\n            for line in f:\n                match = log_pattern.match(line)\n                if match:\n                    data.append(match.groupdict())\n        \n        df = pd.DataFrame(data)\n        return df\n    except FileNotFoundError:\n        return pd.DataFrame()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load logs\ndf_logs = parse_logs_to_df(\"agent_trace.log\")\n\nif not df_logs.empty:\n    # Set display options to read long messages\n    pd.set_option('display.max_colwidth', 150)\n    \n    # 1. Filter for just the 'INFO' or 'ERROR' rows to show in your report\n    display_df = df_logs[df_logs['level'].isin(['INFO', 'ERROR', 'WARNING'])]\n    \n    # Display the last 10 relevant events\n    display(display_df.tail(10))\nelse:\n    print(\"No logs found yet.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**We've covered how to:**\n\n- âœ… Debug agent failures through DEBUG logs \n- âœ… Scale observability with `LoggingPlugin` for production systems\n- âœ… Understand when to use the different logging types","metadata":{}},{"cell_type":"markdown","source":"### Resources\n\n**Refer to the ADK documentation to learn more about observability:**\n\n- [ADK Observability Documentation](https://google.github.io/adk-docs/observability/logging/) - Complete guide to logging in ADK\n- [Custom Plugin](https://google.github.io/adk-docs/plugins/) - Build your own Plugins\n- [External Integrations](https://google.github.io/adk-docs/observability/cloud-trace/) - Explore external third-party observability integrations with ADK","metadata":{"execution":{"iopub.execute_input":"2025-10-24T01:50:15.542601Z","iopub.status.busy":"2025-10-24T01:50:15.542221Z","iopub.status.idle":"2025-10-24T01:50:15.548614Z","shell.execute_reply":"2025-10-24T01:50:15.547556Z","shell.execute_reply.started":"2025-10-24T01:50:15.542577Z"}}}]}